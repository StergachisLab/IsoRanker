{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af7bb5b-93f5-4bcf-860e-bc14f5ed1f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution ~ytz (/mmfs1/gscratch/stergachislab/yhhc/tools/miniconda3/miniconda3/envs/jupyter-notebook/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~atplotlib (/mmfs1/gscratch/stergachislab/yhhc/tools/miniconda3/miniconda3/envs/jupyter-notebook/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ytz (/mmfs1/gscratch/stergachislab/yhhc/tools/miniconda3/miniconda3/envs/jupyter-notebook/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~atplotlib (/mmfs1/gscratch/stergachislab/yhhc/tools/miniconda3/miniconda3/envs/jupyter-notebook/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~andas (/mmfs1/gscratch/stergachislab/yhhc/tools/miniconda3/miniconda3/envs/jupyter-notebook/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting git+https://github.com/yhhc2/IsoRanker.git\n",
      "  Cloning https://github.com/yhhc2/IsoRanker.git to /tmp/pip-req-build-5u1xjzyi\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/yhhc2/IsoRanker.git /tmp/pip-req-build-5u1xjzyi\n",
      "  Resolved https://github.com/yhhc2/IsoRanker.git to commit 9ee93a3800386320bd2cacedb74d1ee761b1cbc0\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pandas>=2.0.0 (from IsoRanker==0.1)\n",
      "  Using cached pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "Collecting numpy>=2.2.2 (from IsoRanker==0.1)\n",
      "  Using cached numpy-2.2.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Collecting matplotlib>=3.10.0 (from IsoRanker==0.1)\n",
      "  Using cached matplotlib-3.10.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting statsmodels>=0.14.4 (from IsoRanker==0.1)\n",
      "  Using cached statsmodels-0.14.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.2 kB)\n",
      "Collecting seaborn>=0.13.2 (from IsoRanker==0.1)\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting scipy>=1.15.1 (from IsoRanker==0.1)\n",
      "  Using cached scipy-1.15.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting pyreadr>=0.4.5 (from IsoRanker==0.1)\n",
      "  Using cached pyreadr-0.5.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Collecting pysam>=0.22.0 (from IsoRanker==0.1)\n",
      "  Using cached pysam-0.23.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting pyhpo>=3.3.0 (from IsoRanker==0.1)\n",
      "  Using cached pyhpo-4.0.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting scikit-learn>=1.6.0 (from IsoRanker==0.1)\n",
      "  Using cached scikit_learn-1.6.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib>=3.10.0->IsoRanker==0.1)\n",
      "  Using cached contourpy-1.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib>=3.10.0->IsoRanker==0.1)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib>=3.10.0->IsoRanker==0.1)\n",
      "  Using cached fonttools-4.56.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (101 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib>=3.10.0->IsoRanker==0.1)\n",
      "  Using cached kiwisolver-1.4.8-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
      "Collecting packaging>=20.0 (from matplotlib>=3.10.0->IsoRanker==0.1)\n",
      "  Using cached packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting pillow>=8 (from matplotlib>=3.10.0->IsoRanker==0.1)\n",
      "  Using cached pillow-11.1.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib>=3.10.0->IsoRanker==0.1)\n",
      "  Using cached pyparsing-3.2.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting python-dateutil>=2.7 (from matplotlib>=3.10.0->IsoRanker==0.1)\n",
      "  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting pytz>=2020.1 (from pandas>=2.0.0->IsoRanker==0.1)\n",
      "  Using cached pytz-2025.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas>=2.0.0->IsoRanker==0.1)\n",
      "  Using cached tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting pydantic>=2 (from pyhpo>=3.3.0->IsoRanker==0.1)\n",
      "  Using cached pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn>=1.6.0->IsoRanker==0.1)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn>=1.6.0->IsoRanker==0.1)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting patsy>=0.5.6 (from statsmodels>=0.14.4->IsoRanker==0.1)\n",
      "  Using cached patsy-1.0.1-py2.py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2->pyhpo>=3.3.0->IsoRanker==0.1)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic>=2->pyhpo>=3.3.0->IsoRanker==0.1)\n",
      "  Using cached pydantic_core-2.27.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting typing-extensions>=4.12.2 (from pydantic>=2->pyhpo>=3.3.0->IsoRanker==0.1)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting six>=1.5 (from python-dateutil>=2.7->matplotlib>=3.10.0->IsoRanker==0.1)\n",
      "  Using cached six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Using cached matplotlib-3.10.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "Using cached numpy-2.2.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.1 MB)\n",
      "Using cached pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB)\n",
      "Using cached pyhpo-4.0.0-py3-none-any.whl (18.2 MB)\n",
      "Using cached pyreadr-0.5.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (418 kB)\n",
      "Using cached pysam-0.23.0-cp312-cp312-manylinux_2_28_x86_64.whl (26.1 MB)\n",
      "Using cached scikit_learn-1.6.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "Using cached scipy-1.15.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.3 MB)\n",
      "Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Using cached statsmodels-0.14.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.7 MB)\n",
      "Using cached contourpy-1.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (323 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached fonttools-4.56.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached kiwisolver-1.4.8-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
      "Using cached packaging-24.2-py3-none-any.whl (65 kB)\n",
      "Using cached patsy-1.0.1-py2.py3-none-any.whl (232 kB)\n",
      "Using cached pillow-11.1.0-cp312-cp312-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "Using cached pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
      "Using cached pydantic_core-2.27.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "Using cached pyparsing-3.2.1-py3-none-any.whl (107 kB)\n",
      "Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "Using cached pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Using cached tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Building wheels for collected packages: IsoRanker\n",
      "  Building wheel for IsoRanker (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for IsoRanker: filename=IsoRanker-0.1-py3-none-any.whl size=26731 sha256=97d8c11ebeb37de6a706078f1ecf2af5702f68a14ac75714e395e6eef3458526\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-0p51k5w5/wheels/17/39/4f/b6e2708e6863c59b43086a63f5df66a1a304fbc0026ba89b39\n",
      "Successfully built IsoRanker\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ytz (/mmfs1/gscratch/stergachislab/yhhc/tools/miniconda3/miniconda3/envs/jupyter-notebook/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~atplotlib (/mmfs1/gscratch/stergachislab/yhhc/tools/miniconda3/miniconda3/envs/jupyter-notebook/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~andas (/mmfs1/gscratch/stergachislab/yhhc/tools/miniconda3/miniconda3/envs/jupyter-notebook/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: pytz, tzdata, typing-extensions, threadpoolctl, six, pysam, pyparsing, pillow, packaging, numpy, kiwisolver, joblib, fonttools, cycler, annotated-types, scipy, python-dateutil, pydantic-core, patsy, contourpy, scikit-learn, pydantic, pandas, matplotlib, statsmodels, seaborn, pyreadr, pyhpo, IsoRanker\n",
      "  Attempting uninstall: tzdata\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution ~ytz (/mmfs1/gscratch/stergachislab/yhhc/tools/miniconda3/miniconda3/envs/jupyter-notebook/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m    WARNING: Ignoring invalid distribution ~atplotlib (/mmfs1/gscratch/stergachislab/yhhc/tools/miniconda3/miniconda3/envs/jupyter-notebook/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: tzdata 2025.1\n",
      "    Uninstalling tzdata-2025.1:\n",
      "      Successfully uninstalled tzdata-2025.1\n",
      "  Attempting uninstall: typing-extensions\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution ~ytz (/mmfs1/gscratch/stergachislab/yhhc/tools/miniconda3/miniconda3/envs/jupyter-notebook/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m    WARNING: Ignoring invalid distribution ~atplotlib (/mmfs1/gscratch/stergachislab/yhhc/tools/miniconda3/miniconda3/envs/jupyter-notebook/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: typing_extensions 4.12.2\n",
      "    Uninstalling typing_extensions-4.12.2:\n",
      "      Successfully uninstalled typing_extensions-4.12.2\n",
      "  Attempting uninstall: threadpoolctl\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution ~ytz (/mmfs1/gscratch/stergachislab/yhhc/tools/miniconda3/miniconda3/envs/jupyter-notebook/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m    WARNING: Ignoring invalid distribution ~atplotlib (/mmfs1/gscratch/stergachislab/yhhc/tools/miniconda3/miniconda3/envs/jupyter-notebook/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m    WARNING: Ignoring invalid distribution ~andas (/mmfs1/gscratch/stergachislab/yhhc/tools/miniconda3/miniconda3/envs/jupyter-notebook/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: threadpoolctl 3.6.0\n",
      "    Uninstalling threadpoolctl-3.6.0:\n",
      "      Successfully uninstalled threadpoolctl-3.6.0\n",
      "  Attempting uninstall: six\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution ~ytz (/mmfs1/gscratch/stergachislab/yhhc/tools/miniconda3/miniconda3/envs/jupyter-notebook/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: six 1.17.0\n",
      "    Uninstalling six-1.17.0:\n",
      "      Successfully uninstalled six-1.17.0\n",
      "  Attempting uninstall: pysam\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution ~ytz (/mmfs1/gscratch/stergachislab/yhhc/tools/miniconda3/miniconda3/envs/jupyter-notebook/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m    WARNING: Ignoring invalid distribution ~atplotlib (/mmfs1/gscratch/stergachislab/yhhc/tools/miniconda3/miniconda3/envs/jupyter-notebook/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m    WARNING: Ignoring invalid distribution ~andas (/mmfs1/gscratch/stergachislab/yhhc/tools/miniconda3/miniconda3/envs/jupyter-notebook/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: pysam 0.23.0\n",
      "    Uninstalling pysam-0.23.0:\n",
      "      Successfully uninstalled pysam-0.23.0\n",
      "  Attempting uninstall: pyparsing\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution ~ytz (/mmfs1/gscratch/stergachislab/yhhc/tools/miniconda3/miniconda3/envs/jupyter-notebook/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m    WARNING: Ignoring invalid distribution ~atplotlib (/mmfs1/gscratch/stergachislab/yhhc/tools/miniconda3/miniconda3/envs/jupyter-notebook/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m    WARNING: Ignoring invalid distribution ~andas (/mmfs1/gscratch/stergachislab/yhhc/tools/miniconda3/miniconda3/envs/jupyter-notebook/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: pyparsing 3.2.1\n",
      "    Uninstalling pyparsing-3.2.1:\n",
      "      Successfully uninstalled pyparsing-3.2.1\n",
      "  Attempting uninstall: pillow\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution ~ytz (/mmfs1/gscratch/stergachislab/yhhc/tools/miniconda3/miniconda3/envs/jupyter-notebook/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: pillow 11.1.0\n",
      "    Uninstalling pillow-11.1.0:\n",
      "      Successfully uninstalled pillow-11.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --force-reinstall git+https://github.com/yhhc2/IsoRanker.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aaadd95-df6c-40c6-b1d5-ed9b292cb4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389cba39-78ff-459b-bb87-d9f10ea58d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import functions from the package\n",
    "from IsoRanker import (\n",
    "    load_data,\n",
    "    filter_based_on_counts,\n",
    "    apply_hypothesis_test,\n",
    "    calculate_z_score,\n",
    "    NMD_test_statistic,\n",
    "    Noncyclo_Expression_Outlier_LOE,\n",
    "    Noncyclo_Expression_Outlier_GOE,\n",
    "    Cyclo_Expression_Outlier_GOE,\n",
    "    NMD_rare_steady_state_transcript,\n",
    "    Noncyclo_Allelic_Imbalance,\n",
    "    Cyclo_Allelic_Imbalance,\n",
    "    calculate_ranks_for_sample,\n",
    "    create_expression_matrix,\n",
    "    create_long_format,\n",
    "    process_hypothesis_test,\n",
    "    update_files_with_haplotype_info,\n",
    "    merge_tsvs_by_keyword, \n",
    "    process_vep_vcf, \n",
    "    merge_haplotype_data, \n",
    "    process_phenotype_data,\n",
    "    process_and_plot_pca,\n",
    "    analyze_isoforms,\n",
    "    process_pileup\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4f3eb3-4b64-42f8-9992-f7d35dec9fe1",
   "metadata": {},
   "source": [
    "## Assign input paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8189eb22-c5f1-42a5-abe8-1299833a1dbc",
   "metadata": {},
   "source": [
    "#### Option 1: If creating expression matrix from PacBio Isoseq pipeline, please uncomment and specify read_stat_path and sample_info_with_haplotype_location_path, otherwise comment out the whole block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5621c1-fdad-459c-856f-e7d68093a697",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Option 1 ##\n",
    "\n",
    "# Provides every single read, which sample each read came from, and the isoform asssociated with each read\n",
    "read_stat_path = \"/mmfs1/gscratch/stergachislab/yhhc/projects/IsoRanker/examples/Expression/Input/read_stats.txt\"\n",
    "\n",
    "# Assigns samples to patients, cyclo/non-cyclo\n",
    "sample_info_path = \"/mmfs1/gscratch/stergachislab/yhhc/projects/IsoRanker/examples/Expression/Input/Sample_info.tsv\"\n",
    "sample_info = pd.read_csv(sample_info_path, sep=\"\\t\")\n",
    "\n",
    "# Create the expression matrix and save it to a file\n",
    "expression_matrix = create_expression_matrix(read_stat_path, output_file=\"expression_matrix.tsv.gz\") # This should NOT be edited if using option 1\n",
    "\n",
    "## Option 1 ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e80900a-6585-4b99-9c78-905563e02c7b",
   "metadata": {},
   "source": [
    "#### Option 2: If using expression matrix directly, please uncomment and specify expression_matrix_path and sample_info_path, otherwise comment out the whole block.\n",
    "- Please see Output/intermediate/expression_matrix.tsv.gz for an example of how to format expression matrix.\n",
    "- Please see Output/intermediate/updated_sample_info.tsv.gz for an example of how to format sample info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842b8bf6-ee55-4d32-83fa-1a82da527179",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Option 2 ##\n",
    "\n",
    "# expression_matrix_path = \"/mmfs1/gscratch/stergachislab/yhhc/projects/IsoRanker/examples/Expression/Output/intermediate/expression_matrix.tsv.gz\"\n",
    "# sample_info_path = \"/mmfs1/gscratch/stergachislab/yhhc/projects/IsoRanker/examples/Expression/Output/intermediate/updated_sample_info.tsv.gz\"\n",
    "\n",
    "# expression_matrix = pd.read_csv(expression_matrix_path, compression = \"gzip\", index_col=0, sep=\"\\t\")\n",
    "# sample_info = pd.read_csv(sample_info_path, compression = \"gzip\", sep=\"\\t\")\n",
    "\n",
    "## Option 2 ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d26b96d-b698-4ab7-9d47-9f695a3679e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provides pigeon annotation for isoforms\n",
    "classification_path = \"/mmfs1/gscratch/stergachislab/yhhc/projects/IsoRanker/examples/Expression/Input/filtered_classification.txt\"\n",
    "classification_data = pd.read_csv(classification_path, sep=\"\\t\")\n",
    "\n",
    "# Provide omim information for genes\n",
    "genemap_path = \"/mmfs1/gscratch/stergachislab/yhhc/projects/IsoRanker_testing/genemap2.txt\"\n",
    "genemap = pd.read_csv(genemap_path, sep='\\t', skiprows=3) # Read the file, skipping the first 3 rows\n",
    "genemap = genemap[genemap['Approved Gene Symbol'].notnull()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8007cb48-f20b-439d-82c4-3bb8e3f6d138",
   "metadata": {},
   "source": [
    "## Convert isoform matrix to long format, then add gene information to enable gene-level analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dce79e2-f105-4dbd-882b-c85b83714177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the long-format dataFrame and adding cyclo/noncyclo as well as haplotype labels and calculate TPM\n",
    "long_format_df = create_long_format(expression_matrix, sample_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e60edba-252d-49df-98a3-38a564315cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the 'isoform' and 'associated_gene' columns from classification_data\n",
    "classification_subset = classification_data[['isoform', 'associated_gene']]\n",
    "# Merge the classification subset with the long_format_df\n",
    "long_format_annotated = long_format_df.merge(\n",
    "    classification_subset,\n",
    "    left_on=\"Isoform\",   # Match isoform IDs in long_format_df\n",
    "    right_on=\"isoform\",  # Match isoform IDs in classification_subset\n",
    "    how=\"left\"           # Keep all rows from long_format_df, even if there's no match in classification_subset\n",
    ").drop(columns=[\"isoform\"])  # Drop redundant 'isoform' column from classification_subset\n",
    "\n",
    "long_format_annotated.to_tsv(\"long_format_annotated.tsv.gz\", index=False, compression = \"gzip\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e6fbe3-4082-4567-858b-9658caf15d3f",
   "metadata": {},
   "source": [
    "## Calculate test stat and rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d55d60b-0c43-4847-9cf5-88b1dde4dfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate for all hypothesis tests\n",
    "test_stat_funcs = [\n",
    "    (\"Noncyclo_LOE\", Noncyclo_Expression_Outlier_LOE),\n",
    "    (\"Noncyclo_GOE\", Noncyclo_Expression_Outlier_GOE)\n",
    "]\n",
    "\n",
    "# Store full results to generate lookup table\n",
    "full_ranked_gene_data = []\n",
    "\n",
    "#Gene level\n",
    "for test_name, test_func in test_stat_funcs:\n",
    "        print(f\"Processing test statistic: {test_name}\")\n",
    "\n",
    "        # Apply the process_hypothesis_test function\n",
    "        ranked_data = process_hypothesis_test(\n",
    "            filtered_data=long_format_annotated, \n",
    "            group_col='Isoform', \n",
    "            test_statistic_func=test_func, \n",
    "            gene_group_col='associated_gene', \n",
    "            gene_level=True, \n",
    "            bin_proportion=0.01, \n",
    "            filter_before_ranking=True, \n",
    "            filter_count_threshold=10)\n",
    "\n",
    "        # Append tuple (test_name, ranked_data) to the list\n",
    "        full_ranked_gene_data.append((test_name, ranked_data))\n",
    "\n",
    "        filtered_ranked_data = ranked_data[ranked_data[\"rank_top_99_5_percentile\"] <= 25]\n",
    "\n",
    "        # Add OMIM data to genes\n",
    "        filtered_ranked_data = filtered_ranked_data.merge(\n",
    "            genemap[['Approved Gene Symbol', 'Phenotypes']],  # Select relevant columns from genemap\n",
    "            how='left',  # Perform a left join to keep all rows from filtered_ranked_data\n",
    "            left_on='associated_gene',  # Column in filtered_ranked_data to join on\n",
    "            right_on='Approved Gene Symbol'  # Column in genemap to join on\n",
    "        )\n",
    "        # Drop the 'Approved Gene Name' column if it is no longer needed\n",
    "        filtered_ranked_data = filtered_ranked_data.drop(columns=['Approved Gene Symbol'])\n",
    "\n",
    "        # Save the results to a tsv file\n",
    "        output_dir = \"\"\n",
    "        output_file = os.path.join(output_dir, f\"{test_name}_gene_top_ranked_data.tsv.gz\")\n",
    "        filtered_ranked_data.to_tsv(output_file, index=False, compression = \"gzip\")\n",
    "        print(f\"Results saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e3d228-f632-47e6-857f-ef1601a01ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stat_funcs = [\n",
    "    (\"Noncyclo_LOE\", Noncyclo_Expression_Outlier_LOE),\n",
    "    (\"Noncyclo_GOE\", Noncyclo_Expression_Outlier_GOE)\n",
    "]\n",
    "\n",
    "#Isoform level\n",
    "for test_name, test_func in test_stat_funcs:\n",
    "        print(f\"Processing test statistic: {test_name}\")\n",
    "\n",
    "        # Apply the process_hypothesis_test function\n",
    "        ranked_data = process_hypothesis_test(\n",
    "            filtered_data=long_format_annotated, \n",
    "            group_col='Isoform', \n",
    "            test_statistic_func=test_func, \n",
    "            gene_group_col='associated_gene', \n",
    "            gene_level=False, \n",
    "            bin_proportion=0.01, \n",
    "            filter_before_ranking=True, \n",
    "            filter_count_threshold=10)\n",
    "\n",
    "        filtered_ranked_data = ranked_data[ranked_data[\"rank_top_99_5_percentile\"] <= 25]\n",
    "\n",
    "        # Add OMIM data to genes\n",
    "        filtered_ranked_data = filtered_ranked_data.merge(\n",
    "            genemap[['Approved Gene Symbol', 'Phenotypes']],  # Select relevant columns from genemap\n",
    "            how='left',  # Perform a left join to keep all rows from filtered_ranked_data\n",
    "            left_on='associated_gene',  # Column in filtered_ranked_data to join on\n",
    "            right_on='Approved Gene Symbol'  # Column in genemap to join on\n",
    "        )\n",
    "        # Drop the 'Approved Gene Name' column if it is no longer needed\n",
    "        filtered_ranked_data = filtered_ranked_data.drop(columns=['Approved Gene Symbol'])\n",
    "\n",
    "        # Save the results to a tsv file\n",
    "        output_dir = \"\"\n",
    "        output_file = os.path.join(output_dir, f\"{test_name}_isoform_top_ranked_data.tsv.gz\")\n",
    "        filtered_ranked_data.to_tsv(output_file, index=False, compression = \"gzip\")\n",
    "        print(f\"Results saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2de41b6-1766-4ae3-b7d7-a98c6091afe9",
   "metadata": {},
   "source": [
    "## Combine all output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486cdd7a-46f5-4a08-a1fb-99726ebf2f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isoform\n",
    "directory = \".\"\n",
    "keyword = \"isoform\" \n",
    "output_tsv = os.path.join(directory, f\"merged_ranked_{keyword}.tsv.gz\")\n",
    "merge_tsvs_by_keyword(directory, keyword, output_tsv)\n",
    "\n",
    "# Gene\n",
    "directory = \".\"\n",
    "keyword = \"gene\"\n",
    "output_tsv = os.path.join(directory, f\"merged_ranked_{keyword}.tsv.gz\")\n",
    "merge_tsvs_by_keyword(directory, keyword, output_tsv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ca6a17-3a04-45a1-a09d-976e386ae418",
   "metadata": {},
   "source": [
    "## Lookup tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6700e753-9159-4ccc-b823-15ae7f77705c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collapse long_format_annotated by summing TPM values per Sample and Gene\n",
    "sample_gene_rankings_lookup_table = long_format_annotated.groupby([\"Sample\", \"associated_gene\"], as_index=False).agg(\n",
    "    {\"Cyclo_TPM\": \"sum\", \"Noncyclo_TPM\": \"sum\"}\n",
    ")\n",
    "\n",
    "# Now merge the ranked gene-level data\n",
    "for test_name, df in full_ranked_gene_data:\n",
    "    # Rename rank column to be test-specific\n",
    "    df_renamed = df.rename(columns={\"rank_top_99_5_percentile\": f\"{test_name}_rank_top_99_5_percentile\"})\n",
    "\n",
    "    # Keep only relevant columns\n",
    "    df_renamed = df_renamed[[\"Sample\", \"associated_gene\", f\"{test_name}_rank_top_99_5_percentile\"]]\n",
    "\n",
    "    # Merge into merged_df using outer join\n",
    "    sample_gene_rankings_lookup_table = pd.merge(sample_gene_rankings_lookup_table, df_renamed, on=[\"Sample\", \"associated_gene\"], how=\"outer\")\n",
    "\n",
    "# Save as a compressed tsv (gzip format)\n",
    "sample_gene_rankings_lookup_table.to_tsv(\"sample_gene_rankings_lookup_table.tsv.gz\", index=False, compression=\"gzip\")\n",
    "\n",
    "# Group by gene (associated_gene) and compute median, Q1 (25th percentile), and Q3 (75th percentile)\n",
    "gene_coverage_lookup_table = sample_gene_rankings_lookup_table.groupby(\"associated_gene\").agg(\n",
    "    Cyclo_TPM_median=(\"Cyclo_TPM\", \"median\"),\n",
    "    Cyclo_TPM_Q1=(\"Cyclo_TPM\", lambda x: x.quantile(0.25)),  # 25th percentile\n",
    "    Cyclo_TPM_Q3=(\"Cyclo_TPM\", lambda x: x.quantile(0.75)),  # 75th percentile\n",
    "    Cyclo_TPM_min=(\"Cyclo_TPM\", \"min\"),  # Minimum value\n",
    "    Cyclo_TPM_max=(\"Cyclo_TPM\", \"max\"),  # Maximum value\n",
    "\n",
    "    Noncyclo_TPM_median=(\"Noncyclo_TPM\", \"median\"),\n",
    "    Noncyclo_TPM_Q1=(\"Noncyclo_TPM\", lambda x: x.quantile(0.25)),  # 25th percentile\n",
    "    Noncyclo_TPM_Q3=(\"Noncyclo_TPM\", lambda x: x.quantile(0.75)),  # 75th percentile\n",
    "    Noncyclo_TPM_min=(\"Noncyclo_TPM\", \"min\"),  # Minimum value\n",
    "    Noncyclo_TPM_max=(\"Noncyclo_TPM\", \"max\")   # Maximum value\n",
    ").reset_index()\n",
    "\n",
    "gene_coverage_lookup_table.to_tsv(\"gene_coverage_lookup_table.tsv.gz\", index=False, compression=\"gzip\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d234832b-47b0-4bdc-962f-04c022296a01",
   "metadata": {},
   "source": [
    "## QC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4918c31a-87a8-4e99-8e68-c92d22677fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "# PCA\n",
    "###################################\n",
    "\n",
    "pca_results = process_and_plot_pca(long_format_annotated, output_pdf=\"pca_plot.pdf\", grouping_col = \"associated_gene\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de83ab30-d708-4338-8c66-cd30b8311637",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "# Gene diversity\n",
    "###################################\n",
    "\n",
    "analyze_isoforms(long_format_annotated, \"gene_diversity.tsv.gz\", \"associated_gene\")\n",
    "\n",
    "###################################\n",
    "# Isoform diversity\n",
    "###################################\n",
    "\n",
    "analyze_isoforms(long_format_annotated, \"isoform_diversity.tsv.gz\", \"Isoform\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf603643-28fe-4b5a-a59b-e552a79c60ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "# Gene diversity plot\n",
    "###################################\n",
    "\n",
    "df = pd.read_csv(\"gene_diversity.tsv.gz\", compression = \"gzip\")\n",
    "\n",
    "# Drop 'Cyclo Total Reads' and 'Noncyclo Total Reads' columns\n",
    "df_filtered = df.drop(columns=[\"Cyclo Total Reads\", \"Noncyclo Total Reads\"])\n",
    "\n",
    "# Define colors for Cyclo and Noncyclo categories\n",
    "cyclo_color = \"red\"\n",
    "noncyclo_color = \"blue\"\n",
    "\n",
    "# Determine a common y-axis limit for all plots\n",
    "y_max = df_filtered.drop(columns=[\"Sample\"]).max().max()\n",
    "\n",
    "# Create subplots for each sample\n",
    "num_samples = len(df_filtered[\"Sample\"])\n",
    "fig, axes = plt.subplots(nrows=num_samples, figsize=(12, num_samples * 3), sharex=True, sharey=True)\n",
    "\n",
    "# If only one sample, make axes iterable\n",
    "if num_samples == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "# Loop through each sample and create a separate bar plot\n",
    "for ax, sample in zip(axes, df_filtered[\"Sample\"]):\n",
    "    sample_data = df_filtered[df_filtered[\"Sample\"] == sample].drop(columns=[\"Sample\"]).T\n",
    "    colors = [cyclo_color if \"Cyclo\" in col else noncyclo_color for col in sample_data.index]\n",
    "    \n",
    "    ax.bar(sample_data.index, sample_data.iloc[:, 0], color=colors)\n",
    "    ax.set_title(f\"Sample: {sample}\")\n",
    "    ax.set_ylabel(\"Count\")\n",
    "    ax.set_ylim(0, y_max)  # Set common y-axis limit\n",
    "    ax.tick_params(axis=\"x\", rotation=90)\n",
    "\n",
    "# Formatting\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save to PDF\n",
    "plt.savefig(\"gene_diversity.pdf\", format=\"pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0c9d7f-96f4-46eb-8c86-f2e84faef79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "# Isoform diversity plot\n",
    "###################################\n",
    "\n",
    "df = pd.read_csv(\"isoform_diversity.tsv.gz\", compression = \"gzip\", sep=\"\\t\")\n",
    "\n",
    "# Drop 'Cyclo Total Reads' and 'Noncyclo Total Reads' columns\n",
    "df_filtered = df.drop(columns=[\"Cyclo Total Reads\", \"Noncyclo Total Reads\"])\n",
    "\n",
    "# Define colors for Cyclo and Noncyclo categories\n",
    "cyclo_color = \"red\"\n",
    "noncyclo_color = \"blue\"\n",
    "\n",
    "# Determine a common y-axis limit for all plots\n",
    "y_max = df_filtered.drop(columns=[\"Sample\"]).max().max()\n",
    "\n",
    "# Create subplots for each sample\n",
    "num_samples = len(df_filtered[\"Sample\"])\n",
    "fig, axes = plt.subplots(nrows=num_samples, figsize=(12, num_samples * 3), sharex=True, sharey=True)\n",
    "\n",
    "# If only one sample, make axes iterable\n",
    "if num_samples == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "# Loop through each sample and create a separate bar plot\n",
    "for ax, sample in zip(axes, df_filtered[\"Sample\"]):\n",
    "    sample_data = df_filtered[df_filtered[\"Sample\"] == sample].drop(columns=[\"Sample\"]).T\n",
    "    colors = [cyclo_color if \"Cyclo\" in col else noncyclo_color for col in sample_data.index]\n",
    "    \n",
    "    ax.bar(sample_data.index, sample_data.iloc[:, 0], color=colors)\n",
    "    ax.set_title(f\"Sample: {sample}\")\n",
    "    ax.set_ylabel(\"Count\")\n",
    "    ax.set_ylim(0, y_max)  # Set common y-axis limit\n",
    "    ax.tick_params(axis=\"x\", rotation=90)\n",
    "\n",
    "# Formatting\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save to PDF\n",
    "plt.savefig(\"isoform_diversity.pdf\", format=\"pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76636b6f-8ccb-45c1-b980-873356980105",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "20fa931a-762b-46e0-8fd3-c000536195e7",
   "metadata": {},
   "source": [
    "## Organizing output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96031cf-574a-4e08-97df-36299bf1907b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Define folder names\n",
    "OUTPUT_FOLDER = \"Output\"\n",
    "QC_FOLDER = os.path.join(OUTPUT_FOLDER, \"qc\")\n",
    "BROWSER_FOLDER = os.path.join(OUTPUT_FOLDER, \"browser\")\n",
    "LOOKUP_TABLES_FOLDER = os.path.join(BROWSER_FOLDER, \"lookup_tables\")\n",
    "COMBINED_RESULTS_FOLDER = os.path.join(BROWSER_FOLDER, \"combined_results\")\n",
    "SEPARATED_RESULTS_FOLDER = os.path.join(BROWSER_FOLDER, \"separated_results\")\n",
    "INTERMEDIATE_FOLDER = os.path.join(OUTPUT_FOLDER, \"intermediate\")\n",
    "\n",
    "# Ensure directories exist\n",
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "os.makedirs(QC_FOLDER, exist_ok=True)\n",
    "os.makedirs(BROWSER_FOLDER, exist_ok=True)\n",
    "os.makedirs(LOOKUP_TABLES_FOLDER, exist_ok=True)\n",
    "os.makedirs(COMBINED_RESULTS_FOLDER, exist_ok=True)\n",
    "os.makedirs(SEPARATED_RESULTS_FOLDER, exist_ok=True)\n",
    "os.makedirs(INTERMEDIATE_FOLDER, exist_ok=True)\n",
    "\n",
    "# Define file categories\n",
    "qc_files = {\n",
    "    \"pca_plot.pdf\",\n",
    "    \"gene_diversity.tsv.gz\",\n",
    "    \"isoform_diversity.tsv.gz\",\n",
    "    \"SRSF6.tsv.gz\",\n",
    "    \"SRSF6_exonic_proportion.pdf\",\n",
    "    \"isoform_diversity.pdf\",\n",
    "    \"gene_diversity.pdf\"\n",
    "}\n",
    "\n",
    "lookup_table_files = {\n",
    "    \"sample_gene_rankings_lookup_table.tsv.gz\",\n",
    "    \"gene_coverage_lookup_table.tsv.gz\"\n",
    "}\n",
    "\n",
    "combined_results_files = {\n",
    "    \"merged_ranked_gene_with_phenotype.tsv.gz\",\n",
    "    \"merged_ranked_isoform_with_phenotype.tsv.gz\",\n",
    "    \"merged_ranked_isoform.tsv.gz\",\n",
    "    \"merged_ranked_gene.tsv.gz\"\n",
    "}\n",
    "\n",
    "separated_results_files = {\n",
    "    \"Cyclo_Allelic_Imbalance_gene_top_ranked_data.tsv.gz\",\n",
    "    \"Cyclo_GOE_gene_top_ranked_data.tsv.gz\",\n",
    "    \"Cyclo_GOE_isoform_top_ranked_data.tsv.gz\",\n",
    "    \"NMD_gene_top_ranked_data.tsv.gz\",\n",
    "    \"NMD_isoform_top_ranked_data.tsv.gz\",\n",
    "    \"NMD_rare_steady_state_transcript_gene_top_ranked_data.tsv.gz\",\n",
    "    \"Noncyclo_GOE_gene_top_ranked_data.tsv.gz\",\n",
    "    \"Noncyclo_GOE_isoform_top_ranked_data.tsv.gz\",\n",
    "    \"Noncyclo_LOE_gene_top_ranked_data.tsv.gz\",\n",
    "    \"Noncyclo_LOE_isoform_top_ranked_data.tsv.gz\",\n",
    "    \"Nonyclo_Allelic_Imbalance_gene_top_ranked_data.tsv.gz\"\n",
    "}\n",
    "\n",
    "browser_files = lookup_table_files | combined_results_files | separated_results_files\n",
    "\n",
    "# Get all `.gz` files in the current directory\n",
    "all_gz_files = {f for f in os.listdir() if f.endswith(\".gz\")}\n",
    "\n",
    "# Find files that should go into intermediate (everything not in QC or Browser)\n",
    "intermediate_files = all_gz_files - qc_files - browser_files\n",
    "\n",
    "# Function to move files\n",
    "def move_files(file_list, destination_folder):\n",
    "    for file in file_list:\n",
    "        if os.path.exists(file):  # Ensure the file exists before moving\n",
    "            shutil.move(file, os.path.join(destination_folder, file))\n",
    "        else:\n",
    "            print(f\"Warning: {file} not found, skipping.\")\n",
    "\n",
    "# Move files to their respective folders\n",
    "move_files(qc_files, QC_FOLDER)\n",
    "move_files(lookup_table_files, LOOKUP_TABLES_FOLDER)\n",
    "move_files(combined_results_files, COMBINED_RESULTS_FOLDER)\n",
    "move_files(separated_results_files, SEPARATED_RESULTS_FOLDER)\n",
    "move_files(intermediate_files, INTERMEDIATE_FOLDER)\n",
    "\n",
    "print(\"File organization complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ac75bd-7e8c-4943-bf0b-a0c8d74d9f69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3642bdbe-d4ae-4f0e-8163-8437d46d7b73",
   "metadata": {},
   "source": [
    "## Zipping/Unzipping all the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf81f4b4-aaa2-4a1a-b87d-8e6bb53ca4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import shutil\n",
    "\n",
    "def unzip_gz_files_recursively(directory, output_dir):\n",
    "    \"\"\"\n",
    "    Recursively unzips all .gz files from `directory` and its subdirectories, \n",
    "    preserving the folder structure in `output_dir`.\n",
    "    \n",
    "    Parameters:\n",
    "    - directory (str): Root directory to search for .gz files.\n",
    "    - output_dir (str): Destination directory where extracted files will be saved.\n",
    "    \"\"\"\n",
    "    for root, _, files in os.walk(directory):  # Recursively walk through directories\n",
    "        for file in files:\n",
    "            if file.endswith(\".gz\"):\n",
    "                gz_path = os.path.join(root, file)\n",
    "                \n",
    "                # Preserve subdirectory structure in the output directory\n",
    "                relative_path = os.path.relpath(root, directory)  # Get relative path\n",
    "                target_dir = os.path.join(output_dir, relative_path)\n",
    "                os.makedirs(target_dir, exist_ok=True)  # Create subdirectories if needed\n",
    "                \n",
    "                output_path = os.path.join(target_dir, file[:-3])  # Remove .gz extension\n",
    "                \n",
    "                # Extract file\n",
    "                with gzip.open(gz_path, 'rb') as gz_file, open(output_path, 'wb') as out_file:\n",
    "                    shutil.copyfileobj(gz_file, out_file)\n",
    "\n",
    "                print(f\"Extracted: {gz_path} -> {output_path}\")\n",
    "\n",
    "# Example usage\n",
    "unzip_gz_files_recursively(\n",
    "    \".\", \n",
    "    \"Output_Unzipped\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fb8ab9-316b-482c-a51e-7844381123ef",
   "metadata": {},
   "source": [
    "## Unit tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3784dc31-64e2-47b3-8102-8d0537efa0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run unit tests\n",
    "# !python -m unittest discover -s /mmfs1/gscratch/stergachislab/yhhc/projects/IsoRanker/tests -p \"test_all.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3beba21-1ad6-48b7-b7e6-a16915b88930",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1f4638-4253-4557-ad09-f3a3a65ce096",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63083257-2648-4164-a4f7-d36a1aa8f7dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
